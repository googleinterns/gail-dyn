08-13 21:03

python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v1" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 6000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_28 --seed 20030 --act_noise 1 --obs_noise 1   \
  --max_tar_vel 2.5  --energy_weight 0.1 --ab 1 --q_pen_weight 0.5  --dq_pen_weight 0.02 --no-dq 1


python -m third_party.a2c_ppo_acktr.enjoy --env-name "LaikagoBulletEnv-v1"  --load-dir trained_models_laika_bullet_28/ppo \
--render 1  --non-det 0  --load-dis 0 --seed 1099 --enlarge_act_range 0 --act_noise 1 --obs_noise 1 --soft_floor_env 0

08-14 17:25
# collect behavior data
python -m third_party.a2c_ppo_acktr.enjoy --env-name "LaikagoBulletEnv-v1"  --load-dir trained_models_laika_bullet_23/ppo  \
--render 0  --non-det 1  --load-dis 0 --seed 109 --enlarge_act_range 1 --act_noise 0 --obs_noise 0 --soft_floor_env 1 \
 --save-traj 1 --save-path "./laika_23_softfloor_n200_2.pkl"


 08-19 12:11
 # randomize init pose
 python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v1" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 6000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_30 --seed 20030 --act_noise 1 --obs_noise 1   \
  --dq_pen_weight 0.02



08-23 23:45
# try low power gap
python -m third_party.a2c_ppo_acktr.enjoy --env-name "LaikagoBulletEnv-v1"  --load-dir trained_models_laika_bullet_23/ppo \
--render 1  --non-det 0  --load-dis 0 --seed 1099 --enlarge_act_range 0 --act_noise 0 --obs_noise 0 --low_power_env 1

# collect behavior data
# low power gap
python -m third_party.a2c_ppo_acktr.enjoy --env-name "LaikagoBulletEnv-v1"  --load-dir trained_models_laika_bullet_23/ppo  \
--render 0  --non-det 1  --load-dis 0 --seed 109 --enlarge_act_range 1 --act_noise 0 --obs_noise 0 --low_power_env 1 \
 --save-traj 1 --save-path "./laika_23_lowpower_n200.pkl"

08-24 15:05
python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v1" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 6000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_32 --seed 20032 --act_noise 1 --obs_noise 1   \
  --max_tar_vel 2.5  --energy_weight 0.1 --ab 8.0 --q_pen_weight 0.5  --dq_pen_weight 0.03 --no-dq 1


08-24 16:53
python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v1" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 6000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_33 --seed 20033 --act_noise 1 --obs_noise 1   \
  --max_tar_vel 2.5  --energy_weight 0.1 --q_pen_weight 0.5  --dq_pen_weight 0.02 --no-dq 1

08-24 20:27
ab - 3.0
dq_pen_weight 0.025
python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v1" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 6000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_34 --seed 20034 --act_noise 1 --obs_noise 1   \
  --max_tar_vel 2.5  --energy_weight 0.1 --q_pen_weight 0.5  --dq_pen_weight 0.025 --no-dq 1

08-24 22:30
# dq,q l2 loss, act l1 loss
python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v1" --num-steps 1200  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 8000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_35 --seed 20035 --act_noise 1 --obs_noise 1   \
  --max_tar_vel 2.5  --energy_weight 0.25 --q_pen_weight 1.0  --dq_pen_weight 0.03 --no-dq 1
08-25 00:01
python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v1" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 10000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_36 --seed 20036 --act_noise 1 --obs_noise 1   \
  --max_tar_vel 2.5  --energy_weight 0.3 --q_pen_weight 0.8  --dq_pen_weight 0.03 --no-dq 1
08-25 09:25
python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v1" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 10000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_37 --seed 20037 --act_noise 1 --obs_noise 1   \
  --max_tar_vel 2.5  --energy_weight 0.4 --q_pen_weight 0.4  --dq_pen_weight 0.03 --no-dq 1

08-25 12:19
# dq,q, act l2 loss,
python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v1" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 10000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_38 --seed 20038 --act_noise 1 --obs_noise 1   \
  --max_tar_vel 2.5  --energy_weight 0.4 --q_pen_weight 0.4  --dq_pen_weight 0.03 --no-dq 1


08-24 20:46
# collect behavior data (feat with q)
python -m third_party.a2c_ppo_acktr.enjoy --env-name "LaikagoBulletEnv-v1"  --load-dir trained_models_laika_bullet_23/ppo  \
--render 0  --non-det 1  --load-dis 0 --seed 109 --enlarge_act_range 1 --act_noise 0 --obs_noise 0 --soft_floor_env 1 \
 --save-traj 1 --save-path "./laika_23_softfloor_n200_feat_wq.pkl"

08-25 09:57
 # collect behavior data (feat with q)
python -m third_party.a2c_ppo_acktr.enjoy --env-name "LaikagoBulletEnv-v1"  --load-dir trained_models_laika_bullet_36/ppo  \
--render 0  --non-det 1  --load-dis 0 --seed 109 --enlarge_act_range 1 --act_noise 0 --obs_noise 0 --soft_floor_env 1 \
 --save-traj 1 --save-path "./laika_36_softfloor_n200_feat_wq.pkl" --no-dq 1


 08-25 13:38
# collect behavior data
# low power gap, new dependent on dq
            max_force_ratio = np.clip(2 - dq/3.0, 0, 1)
            a *= max_force_ratio
# fix soft reset
python -m third_party.a2c_ppo_acktr.enjoy --env-name "LaikagoBulletEnv-v1"  --load-dir trained_models_laika_bullet_23/ppo  \
--render 0  --non-det 1  --load-dis 0 --seed 109 --enlarge_act_range 1 --act_noise 0 --obs_noise 0 --low_power_env 1 \
 --save-traj 1 --save-path "./laika_23_lowpower_dq_n200.pkl"




# new behavior policy disgard attempts(
python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v2" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 10000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_38 --seed 20038 --act_noise 0 --obs_noise 0   \
  --max_tar_vel 2.5  --energy_weight 0.3 --q_pen_weight 0.6  --dq_pen_weight 0.03

python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v2" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 10000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_39 --seed 20039 --act_noise 0 --obs_noise 0   \
  --max_tar_vel 2.5  --energy_weight 0.3 --q_pen_weight 0.8  --dq_pen_weight 0.03

# decrase last pi layer and log std
python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v2" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 10000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_40 --seed 20040 --act_noise 0 --obs_noise 0   \
  --max_tar_vel 2.5  --energy_weight 0.3 --q_pen_weight 0.8  --dq_pen_weight 0.03

python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v2" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 10000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_41 --seed 20041 --act_noise 0 --obs_noise 0   \
  --max_tar_vel 2.5  --energy_weight 0.3 --q_pen_weight 0.8  --dq_pen_weight 0.02 --ab 4

python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v2" --num-steps 1000  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 10000000 --use-linear-lr-decay  \
  --clip-param 0.2 --save-dir trained_models_laika_bullet_42 --seed 20042 --act_noise 0 --obs_noise 0   \
  --max_tar_vel 2.5  --energy_weight 0.2 --q_pen_weight 0.8  --dq_pen_weight 0.02 --ab 3

# back to old reward...
python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v2" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 10000000 --use-linear-lr-decay  \
 --clip-param 0.2 --save-dir trained_models_laika_bullet_43 --seed 20043 --act_noise 0 --obs_noise 0  \
 --max_tar_vel 2.5  --energy_weight 0.1 --ab 4.5 --q_pen_weight 0.5  --dq_pen_weight 0.01

python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v2" --num-steps 1500  --num-processes 8 \
--lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 10000000 --use-linear-lr-decay  \
--clip-param 0.2 --save-dir trained_models_laika_bullet_44 --seed 20044 --act_noise 0 --obs_noise 0  \
--max_tar_vel 2.5  --energy_weight 0.1 --ab 5.0 --q_pen_weight 0.5  --dq_pen_weight 0.02

# try adding entropy; without init scheme
python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v2" --num-steps 1500  --num-processes 8 \
--lr 3e-4 --entropy-coef 0.01 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 10000000 --use-linear-lr-decay  \
--clip-param 0.2 --save-dir trained_models_laika_bullet_44_2 --seed 200442 --act_noise 0 --obs_noise 0  \
--max_tar_vel 2.5  --energy_weight 0.1 --ab 5.0 --q_pen_weight 0.5  --dq_pen_weight 0.02

 # try again
python -m third_party.a2c_ppo_acktr.main --env-name "LaikagoBulletEnv-v2" --num-steps 1500  --num-processes 8 \
 --lr 3e-4 --entropy-coef 0 --ppo-epoch 10 --num-mini-batch 32 --num-env-steps 10000000 --use-linear-lr-decay  \
 --clip-param 0.2 --save-dir trained_models_laika_bullet_45 --seed 20045 --act_noise 0 --obs_noise 0  \
 --max_tar_vel 2.5  --energy_weight 0.1 --ab 5.0 --q_pen_weight 0.4  --dq_pen_weight 0.001
# failed
)


